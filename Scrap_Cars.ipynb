{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scrap_Cars.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLPul00FsP9x",
        "outputId": "67f747df-0e81-4437-d7e0-9f98b04a2fac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7VTl5xopTo2"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/\"\n",
        "import os\n",
        "os.chdir(root_dir + 'Scrap_Cars')\n",
        "\n",
        "#importing necessary libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten,Dropout, Dense,Convolution2D,MaxPooling2D,GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Initiliaze path to the training & testing folder\n",
        "train_dir='Project_Dataset/Train'\n",
        "test_dir='Project_Dataset/Test'\n",
        "\n",
        "\n",
        "###Generating images for Training set\n",
        "train_datagen=ImageDataGenerator(rescale=1./255,\n",
        "                                 rotation_range=40,\n",
        "                                 width_shift_range=0.2,\n",
        "                                 height_shift_range=0.2,\n",
        "                                 shear_range=0.2,\n",
        "                                 zoom_range=0.2,\n",
        "                                 horizontal_flip=True,\n",
        "                                 fill_mode='nearest')\n",
        "###Generating images for Test set\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "###Creating Training set\n",
        "training_set=train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=(150,150),\n",
        "                                               batch_size=10,\n",
        "                                               class_mode='categorical')\n",
        "###Creating validation set\n",
        "test_set=test_datagen.flow_from_directory(test_dir,\n",
        "                                          target_size=(150,150),\n",
        "                                          batch_size=10,\n",
        "                                          class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "\n",
        "#shape printing (splitted dataset)\n",
        "a,b=training_set.next()\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "\n",
        "c,d=test_set.next()\n",
        "print(c.shape)\n",
        "print(d.shape)\n",
        "\n",
        "\n",
        "#data balancing\n",
        "train=training_set.classes\n",
        "class_weights =compute_class_weight(class_weight='balanced',classes=np.unique(train),y=train)\n",
        "class_weights=dict(zip(np.unique(train),class_weights))\n",
        "print(class_weights)\n",
        "\n",
        "#specifying image width and height\n",
        "img_size = 150\n",
        "\n",
        "\n",
        "def model2():\n",
        "    input_shape=(img_size,img_size,3)\n",
        "\n",
        "    base_cnn = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
        "   \n",
        "    model = Sequential()\n",
        "    model.add(base_cnn)\n",
        "    # don't train existing weights\n",
        "    base_cnn.trainable = False\n",
        "\n",
        "    model.add(GlobalMaxPooling2D(name=\"gap\"))\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "def model3():\n",
        "    input_shape=(img_size,img_size,3)\n",
        "\n",
        "    base_cnn = VGG16( weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(base_cnn)\n",
        "    # don't train existing weights\n",
        "    for layer in base_cnn.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.add(GlobalMaxPooling2D(name=\"gap\"))\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "    return model\n",
        "\n",
        "    \n",
        "model=model2()\n",
        "#model=model3()\n",
        "\n",
        "#printing model summary\n",
        "print(model.summary())\n",
        "\n",
        "#compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])\n",
        "\n",
        "#saving the model\n",
        "checkpoint=ModelCheckpoint(\"Project_Saved_Models/model.h5\",\n",
        "                           monitor=\"val_acc\",\n",
        "                           save_best_only=True,\n",
        "                           verbose=1)\n",
        "\n",
        "Epoch=200\n",
        "#training\n",
        "history= model.fit_generator(training_set,\n",
        "                   steps_per_epoch = training_set.__len__()/10,\n",
        "                   epochs = Epoch,\n",
        "                   validation_data = test_set,\n",
        "                   validation_steps = test_set.__len__()/10,\n",
        "                   class_weight=class_weights,\n",
        "                   callbacks=[checkpoint])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#plot accuracy and loss \n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#plt.savefig(\"Project_Extra/cnn_model_acc.png\")\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "#plt.savefig(\"Project_Extra/cnn_model_loss.png\")\n"
      ]
    }
  ]
}